---
layout:     post
title:      特征工程
subtitle:   天池比赛二手车交易价格预测
date:       2020-03-26
author:     Young
header-img: img/bg-post/1*EbpKczfURCvAF6uUp_Hhew.jpeg
catalog: true
tags:
    - tianchi
---

### 常见的特征工程包括
> 1. 异常处理：
>    - 通过箱线图（或 3-Sigma）分析删除异常值；
>    - BOX-COX 转换（处理有偏分布）；
>    - 长尾截断；
> 2. 特征归一化/标准化：
>    - 标准化（转换为标准正态分布）；
>    - 归一化（抓换到 [0,1] 区间）；
>    - 针对幂律分布，可以采用公式： 𝑙𝑜𝑔(1+𝑥1+𝑚𝑒𝑑𝑖𝑎𝑛)log(1+x1+median)
> 3. 数据分桶：
>    - 等频分桶；
>    - 等距分桶；
>    - Best-KS 分桶（类似利用基尼指数进行二分类）；
>    - 卡方分桶；
> 4. 缺失值处理：
>    - 不处理（针对类似 XGBoost 等树模型）；
>    - 删除（缺失数据太多）；
>    - 插值补全，包括均值/中位数/众数/建模预测/多重插补/压缩感知补全/矩阵补全等；
>    - 分箱，缺失值一个箱；
> 5. 特征构造：
>    - 构造统计量特征，报告计数、求和、比例、标准差等；
>    - 时间特征，包括相对时间和绝对时间，节假日，双休日等；
>    - 地理信息，包括分箱，分布编码等方法；
>    - 非线性变换，包括 log/ 平方/ 根号等；
>    - 特征组合，特征交叉；
>    - 仁者见仁，智者见智。
> 6. 特征筛选
>    - 过滤式（filter）：先对数据进行特征选择，然后在训练学习器，常见的方法有 Relief/方差选择发/相关系数法/卡方检验法/互信息法；
>    - 包裹式（wrapper）：直接把最终将要使用的学习器的性能作为特征子集的评价准则，常见方法有 LVM（Las Vegas Wrapper） ；
>    - 嵌入式（embedding）：结合过滤式和包裹式，学习器训练过程中自动进行了特征选择，常见的有 lasso 回归；
> 7. 降维
>    - PCA/ LDA/ ICA；
>    - 特征选择也是一种降维。

### 异常值的识别与删除

> **箱线图**
>
> 箱线图技术实际上就是**利用数据的分位数识别其中的异常点**，该图形属于典型的统计图形，在学术界和工业界都得到广泛的应用。
>
> 图中的下四分位数指的是数据的25%分位点所对应的值（Q1）；中位数即为数据的50%分位点所对应的值（Q2）；上四分位数则为数据的75%分位点所对应的值（Q3）；上须的计算公式为Q3+1.5(Q3-Q1)；下须的计算公式为Q1-1.5(Q3-Q1)。其中，Q3-Q1表示四分位差。如果采用箱线图识别异常值，其判断标准是，当变量的数据值大于箱线图的上须或者小于箱线图的下须时，就可以认为这样的数据点为异常点（极端异常点）。

![](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/nLL9Ii.jpg)

![](https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/Br1Nzx.jpg)

```python
def outliers_proc(data, col_name, scale=3):
    """
    用于清洗异常值，默认用 box_plot（scale=3）进行清洗极端异常点
    :param data: 接收 pandas 数据格式
    :param col_name: pandas 列名
    :param scale: 尺度
    :return:
    """

    def box_plot_outliers(data_ser, box_scale):
        """
        利用箱线图去除异常值
        :param data_ser: 接收 pandas.Series 数据格式
        :param box_scale: 箱线图尺度，
        :return:
        """
        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))
        val_low = data_ser.quantile(0.25) - iqr
        val_up = data_ser.quantile(0.75) + iqr
        rule_low = (data_ser < val_low)
        rule_up = (data_ser > val_up)
        return (rule_low, rule_up), (val_low, val_up)

    data_n = data.copy()
    data_series = data_n[col_name]
    rule, value = box_plot_outliers(data_series, box_scale=scale)
    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]
    print("Delete number is: {}".format(len(index)))
    data_n = data_n.drop(index)
    data_n.reset_index(drop=True, inplace=True)
    print("Now column number is: {}".format(data_n.shape[0]))
    index_low = np.arange(data_series.shape[0])[rule[0]]
    outliers = data_series.iloc[index_low]
    print("Description of data less than the lower bound is:")
    print(pd.Series(outliers).describe())
    index_up = np.arange(data_series.shape[0])[rule[1]]
    outliers = data_series.iloc[index_up]
    print("Description of data larger than the upper bound is:")
    print(pd.Series(outliers).describe())
    
    fig, ax = plt.subplots(1, 2, figsize=(10, 7))
    sns.boxplot(y=data[col_name], data=data, palette="Set1", ax=ax[0])
    sns.boxplot(y=data_n[col_name], data=data_n, palette="Set1", ax=ax[1])
    return data_n
```

> 对数字特征 power 进行异常值清洗

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/Lxt6S7.png" alt="清洗前 vs 清洗后" style="zoom:50%;" />

> **3∂原则**
>
> 这个原则有个条件：**数据需要服从正态分布**。在3∂原则下，异常值如超过3倍标准差，那么可以将其视为异常值。正负3∂的概率是99.7%，那么距离平均值3∂之外的值出现的概率为$P( \midx-u \mid > 3∂) \leq 0.003$，属于极个别的小概率事件。如果数据不服从正态分布，也可以用远离平均值的多少倍标准差来描述。红色箭头所指就是异常值。

<img src="https://gitee.com/echisenyang/GiteeForUpicUse/raw/master/uPic/XfX9Ls.jpg"/>

### 特征构造

我们从EDA学到了啥？？？？

> 现在我们已经探索了数据中的趋势和关系，我们可以为我们的模型设计一组函数。 我们可以使用EDA的结果来构建特征工程。 特别是，**我们从EDA学到了以下知识，可以帮助我们进行特征工程/选择**：
>
> - 分数分布因建筑类型而异，并且在较小程度上因行政区而异。 虽然我们将关注数字特征，但我们还应该在模型中包含这两个分类特征。
> - 对特征进行对数变换不会导致特征与分数之间的线性相关性显着增加

| 数据使用                      | **Field**         | **Description**                                              | 数据情况                                                     |
| :---------------------------- | :---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|                               | SaleID            | 交易ID，唯一编码                                             | 唯一编码                                                     |
|                               | name              | 汽车交易名称，已脱敏                                         | 【无有效信息】                                               |
| 合并特征，构建新特征used_time | ~~regDate~~       | 汽车注册日期，例如20160101，2016年01月01日                   | 最早注册日期19910001、最晚20151212                           |
|                               | model             | 车型编码，已脱敏                                             | [0-247] 种车型【有缺失值】                                   |
| 计算统计量                    | brand             | 汽车品牌，已脱敏                                             | [0-39] 种品牌                                                |
|                               | bodyType          | 车身类型：豪华轿车：0，微型车：1，厢型车：2，大巴车：3，敞篷车：4，双门汽车：5，商务车：6，搅拌车：7 | [0-7] 种车身类型【有缺失值】                                 |
|                               | fuelType          | 燃油类型：汽油：0，柴油：1，液化石油气：2，天然气：3，混合动力：4，其他：5，电动：6 | [0-6] 种燃油类型【有缺失值】                                 |
|                               | gearbox           | 变速箱：手动：0，自动：1                                     | [0-1] 种变速箱【有缺失值】                                   |
| 数据分桶                      | power             | 发动机功率：范围 [ 0, 600 ]                                  | max值19312【该字段存在异常值】                               |
|                               | kilometer         | 汽车已行驶公里，单位万km                                     | [0-15] 万行驶里程                                            |
|                               | notRepairedDamage | 汽车有尚未修复的损坏：是：0，否：1                           | [0-1] 是否损坏                                               |
| 提取特征[:-3]                 | ~~regionCode~~    | 地区编码，已脱敏                                             |                                                              |
| 无效特征                      | ~~seller~~        | ~~销售方：个体：0，非个体：1~~                               | ~~[0-1] 种销售【无有效信息】【数据倾斜】~~                   |
| 无效特征                      | ~~offerType~~     | ~~报价类型：提供：0，请求：1~~                               | ~~最大值为0【无有效信息】【数据倾斜】~~                      |
| 合并特征，构建新特征used_time | ~~creatDate~~     | 汽车上线时间，即开始售卖时间                                 | 最早售卖日期20150618、最晚20160407                           |
| 计算统计量                    | price             | 二手车交易价格（预测目标）                                   | 最大值99999，与75%中位数7700差距较大【该字段存在异常值】     |
|                               | v系列特征         | 匿名特征，包含v0-14在内15个匿名特征                          | v_2,v_3,v_4,v_10,v_11,v_12,v_13,v_14【最大值与75%中位数和均值差距较大】 |

> 1）合并特征：
>
> 使用时间：data['creatDate'] - data['regDate']，反应汽车使用时间，一般来说价格与使用时间成反比
>
> -  看一下空数据，有 15k 个样本的时间是有问题的，我们可以选择删除，也可以选择放着。
> 但是这里不建议删除，因为**删除缺失数据占总样本量过大**，7.5%。我们可以先放着，因为如果我们 XGBoost 之类的决策树，其本身就能处理缺失值，所以可以不用管；
>
> 2）提取特征：
>
> 从邮编中提取城市信息，相当于加入了先验知识
>
> 3）计算某一特征的统计量信息
>
> 从汽车品牌与二手车交易价格计算某品牌的（销售，价格）统计量
>
> ⚠️ 二手车交易价格为测试集独有，这里的思路为将测试集关于（销售，价格）统计量特征通过`pd.merge(brand_fe, how='left', on='brand')`的方式运用到训练集上【这里存疑❓】
>
> 4）数据分桶
>
> 以 power 为例，这时候我们的缺失值也进桶了，为什么要做数据分桶呢，原因有很多，= =
>
> `bin = [i*10 for i in range(31)]
> data['power_bin'] = pd.cut(data['power'], bin, labels=False)`
>
> 1. 离散后稀疏向量内积乘法运算速度更快，计算结果也方便存储，容易扩展；
> 2. 离散后的特征对异常值更具鲁棒性，如 age>30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；
> 3. LR 属于广义线性模型，表达能力有限，经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；
> 4. 离散后特征可以进行特征交叉，提升表达能力，由 M+N 个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；
> 5. 特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化



